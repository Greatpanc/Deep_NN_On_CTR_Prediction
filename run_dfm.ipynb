{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#======config=========\n",
    "\n",
    "SUB_DIR = \"./\"\n",
    "\n",
    "\n",
    "NUM_SPLITS = 3\n",
    "RANDOM_SEED = 233\n",
    "\n",
    "# types of columns of the dataset dataframe\n",
    "CATEGORICAL_COLS = [\n",
    "   'pass_identity', #category\n",
    "'bdg_age_range',#category\n",
    "'eight_crowd', #category\n",
    "'bdg_consumption_level', #category\n",
    "'h_channels_s',#category\n",
    "'setup_ele',#category\n",
    "'setup_meituan',#category\n",
    "'bdg_professioin',#category \n",
    "'poi_1',\n",
    "'poi_2',\n",
    "'poi_3',\n",
    "'poi_4',\n",
    "'poi_5',\n",
    "]\n",
    "\n",
    "NUMERIC_COLS = ['user_health_value',\n",
    "'privilege_sensitive',\n",
    "'avg_total_price_a',\n",
    "'avg_total_price_q',\n",
    "'avg_total_price_m',\n",
    "'avg_total_price_s',\n",
    "'avg_pay_price_a',\n",
    "'avg_pay_price_q',\n",
    "'avg_pay_price_m',\n",
    "'avg_pay_price_s',\n",
    "'wuyouhui_order_ratio_a',\n",
    "'wuyouhui_order_ratio_q',\n",
    "'wuyouhui_order_ratio_m',\n",
    "'wuyouhui_order_ratio_s',\n",
    "'order_rate',\n",
    "'privilege_sensitive.1',\n",
    "'next_month_avg_ue',\n",
    "'this_month_avg_ue',\n",
    "'price_preference_score',\n",
    "'service_preference_score',\n",
    "'resource_preference_score',\n",
    "'total_coupon_price',\n",
    "'total_coupon_balance',\n",
    "'total_coupon_used_ratio_a',\n",
    "'total_coupon_used_ratio_q',\n",
    "'total_coupon_used_ratio_m',\n",
    "'total_coupon_used_ratio_s',\n",
    "'price_preference_score.1',\n",
    "'visit_frequency_q',\n",
    "'total_order_q',\n",
    "'net_worth_score',\n",
    "'wuliu_order_ratio_a',\n",
    "'total_shop_butie_ratio_m',\n",
    "'tizao_total_order_dinner_q',\n",
    "'shop_concentration_q',\n",
    "'avg_profit_a',\n",
    "'sum_shop_butie_m',\n",
    "'first_day',\n",
    "'tizao_med_pay_price_dinner_q',\n",
    "'total_shop_butie_ratio_q',\n",
    "'sum_shop_butie_s',\n",
    "'max_delivery_price_m',\n",
    "'total_shop_butie_ratio_a',\n",
    "'min_delivery_price_q',\n",
    "'max_delivery_price_a',\n",
    "'avg_net_profit_a',\n",
    "'max_delivery_price_q',\n",
    "'avg_wuliu_take_out_time_s',\n",
    "'avg_wuliu_take_out_time_q',\n",
    "'avg_wuliu_dis_s',\n",
    "'last_delay_day_a',\n",
    "'shop_concentration_a',\n",
    "'loss_ratio_q',\n",
    "'avg_net_profit_q',\n",
    "'tizao_avg_pay_price_dinner_q',\n",
    "'min_delivery_price_a',\n",
    "'loss_ratio_m',\n",
    "'tizao_total_order_dinner_s',\n",
    "'lat_1',\n",
    "'lat_2',\n",
    "'lat_3',\n",
    "'lat_4',\n",
    "'lat_5',\n",
    "'lat_6',\n",
    "'lat_7',\n",
    "'lat_8',\n",
    "'lat_9',\n",
    "'lat_10',\n",
    "'lng_1',\n",
    "'lng_2',\n",
    "'lng_3',\n",
    "'lng_4',\n",
    "'lng_5',\n",
    "'lng_6',\n",
    "'lng_7',\n",
    "'lng_8',\n",
    "'lng_9',\n",
    "'lng_10',\n",
    "'doc_0',\n",
    "'doc_1',\n",
    "'doc_2',\n",
    "'doc_3',\n",
    "'doc_4',\n",
    "'doc_5',\n",
    "'doc_6',\n",
    "'doc_7',\n",
    "'doc_8',\n",
    "'doc_9',\n",
    "'doc_10',\n",
    "'doc_11',\n",
    "'doc_12',\n",
    "'doc_13',\n",
    "'doc_14',\n",
    "'doc_15',\n",
    "'doc_16',\n",
    "'doc_17',\n",
    "'doc_18',\n",
    "'doc_19',\n",
    "]\n",
    "\n",
    "IGNORE_COLS = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gini(actual, pred):\n",
    "    assert (len(actual) == len(pred))\n",
    "    #np.c_是按行连接两个矩阵，就是把两矩阵左右相加，要求行数相等，类似于pandas中的merge()。\n",
    "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
    "    #np.arange创建等差数组，其实是生成index:0~n-1\n",
    "    #pred 列取负数：-1 * all[:, 1]\n",
    "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]  #把pred列的分数由高到低排序\n",
    "    totalLosses = all[:, 0].sum()\n",
    "    giniSum = all[:, 0].cumsum().sum() / totalLosses\n",
    "\n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    "\n",
    "def gini_norm(actual, pred):\n",
    "    return gini(actual, pred) / gini(actual, actual)\n",
    "\n",
    "\n",
    "def custom_error(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    \n",
    "\n",
    "    return 'gini_norm',gini_norm(labels,preds)\n",
    "\n",
    "\n",
    "df_train = shuffle(pd.read_pickle(\"./df_train_scaled.pickle\"))\n",
    "#标准化连续值\n",
    "df_train[NUMERIC_COLS] = StandardScaler().fit_transform(df_train[NUMERIC_COLS])\n",
    "train_X,test_X = train_test_split(df_train,test_size = 0.2,random_state = 233)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==========data_reader========\n",
    "\n",
    "class FeatureDictionary(object):\n",
    "    def __init__(self, trainfile=None, testfile=None,\n",
    "                 dfTrain=None, dfTest=None, numeric_cols=[], ignore_cols=[]):\n",
    "        assert not ((trainfile is None) and (dfTrain is None)), \"trainfile or dfTrain at least one is set\"\n",
    "        assert not ((trainfile is not None) and (dfTrain is not None)), \"only one can be set\"\n",
    "        assert not ((testfile is None) and (dfTest is None)), \"testfile or dfTest at least one is set\"\n",
    "        assert not ((testfile is not None) and (dfTest is not None)), \"only one can be set\"\n",
    "        self.trainfile = trainfile\n",
    "        self.testfile = testfile\n",
    "        self.dfTrain = dfTrain\n",
    "        self.dfTest = dfTest\n",
    "        self.numeric_cols = numeric_cols\n",
    "        self.ignore_cols = ignore_cols\n",
    "        self.gen_feat_dict()\n",
    "\n",
    "    def gen_feat_dict(self):\n",
    "        if self.dfTrain is None:\n",
    "            dfTrain = pd.read_csv(self.trainfile)\n",
    "        else:\n",
    "            dfTrain = self.dfTrain\n",
    "        if self.dfTest is None:\n",
    "            dfTest = pd.read_csv(self.testfile)\n",
    "        else:\n",
    "            dfTest = self.dfTest\n",
    "        df = pd.concat([dfTrain, dfTest]) #首尾相连\n",
    "        self.feat_dict = {}\n",
    "        tc = 0\n",
    "        for col in df.columns:\n",
    "            if col in self.ignore_cols:\n",
    "                continue\n",
    "            if col in self.numeric_cols:\n",
    "                # map to a single index\n",
    "                self.feat_dict[col] = tc\n",
    "                tc += 1\n",
    "            else:\n",
    "                us = df[col].unique()\n",
    "                self.feat_dict[col] = dict(zip(us, range(tc, len(us)+tc)))\n",
    "                tc += len(us)\n",
    "        self.feat_dim = tc\n",
    "\n",
    "\n",
    "class DataParser(object):\n",
    "    def __init__(self, feat_dict):\n",
    "        self.feat_dict = feat_dict\n",
    "\n",
    "    def parse(self, infile=None, df=None, has_label=False):\n",
    "        assert not ((infile is None) and (df is None)), \"infile or df at least one is set\"\n",
    "        assert not ((infile is not None) and (df is not None)), \"only one can be set\"\n",
    "        if infile is None:\n",
    "            dfi = df.copy()\n",
    "        else:\n",
    "            dfi = pd.read_csv(infile)\n",
    "        if has_label:\n",
    "            y = dfi[\"l3\"].values.tolist()\n",
    "            dfi.drop([\"l3\"], axis=1, inplace=True)\n",
    "        else:\n",
    "            ids = dfi.index.tolist()\n",
    "            \n",
    "        # dfi for feature index\n",
    "        # dfv for feature value which can be either binary (1/0) or float (e.g., 10.24)\n",
    "        dfv = dfi.copy()\n",
    "        for col in dfi.columns:\n",
    "            if col in self.feat_dict.ignore_cols:\n",
    "                dfi.drop(col, axis=1, inplace=True)\n",
    "                dfv.drop(col, axis=1, inplace=True)\n",
    "                continue\n",
    "            \n",
    "            if col in self.feat_dict.numeric_cols:\n",
    "                dfi[col] = self.feat_dict.feat_dict[col]\n",
    "            else:\n",
    "                dfi[col] = dfi[col].map(self.feat_dict.feat_dict[col])\n",
    "                dfv[col] = 1.\n",
    "\n",
    "        # list of list of feature indices of each sample in the dataset\n",
    "        Xi = dfi.values.tolist()\n",
    "        # list of list of feature values of each sample in the dataset\n",
    "        Xv = dfv.values.tolist()\n",
    "        if has_label:\n",
    "            return Xi, Xv, y\n",
    "        else:\n",
    "            return Xi, Xv, ids\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "\n",
    "gini_scorer = make_scorer(gini_norm, greater_is_better=True, needs_proba=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def _load_data():\n",
    "    \n",
    "    \n",
    "    dfTrain = train_X\n",
    "    #dfTest = \n",
    "\n",
    "\n",
    "    cols = [c for c in dfTrain.columns if c not in [\"l3\"]]\n",
    "\n",
    "    X_train = dfTrain[cols].values\n",
    "    y_train = dfTrain[\"l3\"].values\n",
    "    dfTest = test_X[cols]\n",
    "    X_test = dfTest[cols].values\n",
    "    ids_test = dfTest.index.tolist()\n",
    "    cat_features_indices = [i for i,c in enumerate(cols) if c in CATEGORICAL_COLS]\n",
    "\n",
    "    return dfTrain, dfTest, X_train, y_train, X_test, ids_test, cat_features_indices\n",
    "\n",
    "\n",
    "def _run_base_model_dfm(dfTrain, dfTest, folds, dfm_params):\n",
    "    fd = FeatureDictionary(dfTrain=dfTrain, dfTest=dfTest,\n",
    "                           numeric_cols=NUMERIC_COLS,\n",
    "                           ignore_cols=IGNORE_COLS)\n",
    "    data_parser = DataParser(feat_dict=fd)\n",
    "    Xi_train, Xv_train, y_train = data_parser.parse(df=dfTrain, has_label=True)\n",
    "    Xi_test, Xv_test, ids_test = data_parser.parse(df=dfTest)\n",
    "\n",
    "    dfm_params[\"feature_size\"] = fd.feat_dim\n",
    "    dfm_params[\"field_size\"] = len(Xi_train[0])\n",
    "\n",
    "    y_train_meta = np.zeros((dfTrain.shape[0], 1), dtype=float)\n",
    "    y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)\n",
    "    _get = lambda x, l: [x[i] for i in l]\n",
    "    gini_results_cv = np.zeros(len(folds), dtype=float)\n",
    "    gini_results_epoch_train = np.zeros((len(folds), dfm_params[\"epoch\"]), dtype=float)\n",
    "    gini_results_epoch_valid = np.zeros((len(folds), dfm_params[\"epoch\"]), dtype=float)\n",
    "\n",
    "    for i, (train_idx, valid_idx) in enumerate(folds):\n",
    "        #valid_idx = valid_idx[:1024]\n",
    "        Xi_train_, Xv_train_, y_train_ = _get(Xi_train, train_idx), _get(Xv_train, train_idx), _get(y_train, train_idx)\n",
    "        Xi_valid_, Xv_valid_, y_valid_ = _get(Xi_train, valid_idx), _get(Xv_train, valid_idx), _get(y_train, valid_idx)\n",
    "\n",
    "        dfm = DeepFM(**dfm_params)\n",
    "        dfm.fit(Xi_train_, Xv_train_, y_train_, Xi_valid_, Xv_valid_, y_valid_)\n",
    "        #dfm.fit(Xi_train_, Xv_train_, y_train_, Xi_valid_, Xv_valid_, y_valid_,early_stopping=True)\n",
    "        y_train_meta[valid_idx,0]= dfm.predict(Xi_valid_, Xv_valid_)\n",
    "        y_test_meta[:,0] += dfm.predict(Xi_test, Xv_test)\n",
    "\n",
    "        gini_results_cv[i] = gini_norm(y_valid_, y_train_meta[valid_idx])\n",
    "        gini_results_epoch_train[i] = dfm.train_result\n",
    "        gini_results_epoch_valid[i] = dfm.valid_result\n",
    "\n",
    "    y_test_meta /= float(len(folds))\n",
    "\n",
    "    # save result\n",
    "    if dfm_params[\"use_fm\"] and dfm_params[\"use_deep\"]:\n",
    "        clf_str = \"DeepFM\"\n",
    "    elif dfm_params[\"use_fm\"]:\n",
    "        clf_str = \"FM\"\n",
    "    elif dfm_params[\"use_deep\"]:\n",
    "        clf_str = \"DNN\"\n",
    "    print(\"%s: %.5f (%.5f)\"%(clf_str, gini_results_cv.mean(), gini_results_cv.std()))\n",
    "    filename = \"%s_Mean%.5f_Std%.5f.csv\"%(clf_str, gini_results_cv.mean(), gini_results_cv.std())\n",
    "    _save_result(ids_test, y_test_meta, filename)\n",
    "\n",
    "    _plot_fig(gini_results_epoch_train, gini_results_epoch_valid, clf_str)\n",
    "\n",
    "    return y_train_meta, y_test_meta\n",
    "\n",
    "def _save_result(ids, y_pred, filename=\"dfm_res.csv\"):\n",
    "    pd.DataFrame({\"id\": ids, \"target\": y_pred.flatten()}).to_csv(\n",
    "    os.path.join(SUB_DIR, filename), index=False, float_format=\"%.5f\")\n",
    "\n",
    "\n",
    "\n",
    "def _plot_fig(train_results, valid_results, model_name):\n",
    "    colors = [\"red\", \"blue\", \"green\"]\n",
    "    xs = np.arange(1, train_results.shape[1]+1)\n",
    "    plt.figure()\n",
    "    legends = []\n",
    "    for i in range(train_results.shape[0]):\n",
    "        plt.plot(xs, train_results[i], color=colors[i], linestyle=\"solid\", marker=\"o\")\n",
    "        plt.plot(xs, valid_results[i], color=colors[i], linestyle=\"dashed\", marker=\"o\")\n",
    "        legends.append(\"train-%d\"%(i+1))\n",
    "        legends.append(\"valid-%d\"%(i+1))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Normalized Gini\")\n",
    "    plt.title(\"%s\"%model_name)\n",
    "    plt.legend(legends)\n",
    "    plt.savefig(\"./fig/%s.png\"%model_name)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from DeepFM import DeepFM\n",
    "from ipykernel import kernelapp as app\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(actual, pred):\n",
    "    dfm_res= []\n",
    "    for i in pred:\n",
    "        if i >0.5:\n",
    "            dfm_res.append(1)\n",
    "        else:\n",
    "            dfm_res.append(0)\n",
    "    print \"pred: %d , actual: %d , total : %d\" % (sum(dfm_res),sum(actual),len(pred))\n",
    "    \n",
    "    s = sklearn.metrics.accuracy_score(actual,dfm_res)\n",
    "    return s\n",
    "def gini_norm(actual, pred):\n",
    "    dfm_res= []\n",
    "    for i in pred:\n",
    "        if i >0.5:\n",
    "            dfm_res.append(1)\n",
    "        else:\n",
    "            dfm_res.append(0)\n",
    "    print \"pred: %d , actual: %d , total : %d\" % (sum(dfm_res),sum(actual),len(pred))\n",
    "    return gini(actual, pred) / gini(actual, actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "dfTrain, dfTest, X_train, y_train, X_test, ids_test, cat_features_indices = _load_data()\n",
    "\n",
    "# folds\n",
    "folds = list(StratifiedKFold(n_splits=NUM_SPLITS, shuffle=True,\n",
    "                             random_state=RANDOM_SEED).split(X_train, y_train))\n",
    "fd = FeatureDictionary(dfTrain=dfTrain, dfTest=dfTest,\n",
    "                           numeric_cols=NUMERIC_COLS,\n",
    "                           ignore_cols=IGNORE_COLS)\n",
    "data_parser = DataParser(feat_dict=fd)\n",
    "Xi_train, Xv_train, y_train = data_parser.parse(df=dfTrain, has_label=True)\n",
    "Xi_test, Xv_test, ids_test = data_parser.parse(df=dfTest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79996, 111), (79996, 111), (19999, 111), (19999, 111))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Xi_train).shape,np.array(Xv_train).shape,np.array(Xi_test).shape,np.array(Xv_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#params: 765214\n",
      "pred: 8033 , actual: 10660 , total : 53330\n",
      "pred: 3944 , actual: 5331 , total : 26666\n",
      "[1] train-result=0.7680, valid-result=0.7543 [8.3 s]\n",
      "pred: 9347 , actual: 10660 , total : 53330\n",
      "pred: 4710 , actual: 5331 , total : 26666\n",
      "[2] train-result=0.8349, valid-result=0.7991 [8.1 s]\n",
      "pred: 9861 , actual: 10660 , total : 53330\n",
      "pred: 4886 , actual: 5331 , total : 26666\n",
      "[3] train-result=0.8969, valid-result=0.8317 [8.1 s]\n",
      "pred: 9507 , actual: 10660 , total : 53330\n",
      "pred: 4696 , actual: 5331 , total : 26666\n",
      "[4] train-result=0.9345, valid-result=0.8383 [8.1 s]\n",
      "pred: 9182 , actual: 10660 , total : 53330\n",
      "pred: 4401 , actual: 5331 , total : 26666\n",
      "[5] train-result=0.9587, valid-result=0.8359 [9.1 s]\n",
      "pred: 10541 , actual: 10660 , total : 53330\n",
      "pred: 5546 , actual: 5331 , total : 26666\n",
      "[6] train-result=0.9638, valid-result=0.8349 [8.0 s]\n",
      "pred: 9715 , actual: 10660 , total : 53330\n",
      "pred: 4688 , actual: 5331 , total : 26666\n",
      "[7] train-result=0.9802, valid-result=0.8341 [8.2 s]\n",
      "pred: 10069 , actual: 10660 , total : 53330\n",
      "pred: 5044 , actual: 5331 , total : 26666\n",
      "[8] train-result=0.9839, valid-result=0.8274 [8.2 s]\n",
      "pred: 10305 , actual: 10660 , total : 53330\n",
      "pred: 4905 , actual: 5331 , total : 26666\n",
      "[9] train-result=0.9903, valid-result=0.8100 [8.2 s]\n",
      "pred: 10528 , actual: 10660 , total : 53330\n",
      "pred: 5293 , actual: 5331 , total : 26666\n",
      "[10] train-result=0.9919, valid-result=0.8079 [8.3 s]\n",
      "pred: 5290 , actual: 5331 , total : 26666\n",
      "#params: 765214\n",
      "pred: 9621 , actual: 10661 , total : 53331\n",
      "pred: 4924 , actual: 5330 , total : 26665\n",
      "[1] train-result=0.7868, valid-result=0.7766 [7.9 s]\n",
      "pred: 11382 , actual: 10661 , total : 53331\n",
      "pred: 5799 , actual: 5330 , total : 26665\n",
      "[2] train-result=0.8877, valid-result=0.8423 [8.1 s]\n",
      "pred: 10695 , actual: 10661 , total : 53331\n",
      "pred: 5531 , actual: 5330 , total : 26665\n",
      "[3] train-result=0.9368, valid-result=0.8506 [8.1 s]\n",
      "pred: 9707 , actual: 10661 , total : 53331\n",
      "pred: 4559 , actual: 5330 , total : 26665\n",
      "[4] train-result=0.9674, valid-result=0.8439 [9.0 s]\n",
      "pred: 10272 , actual: 10661 , total : 53331\n",
      "pred: 5328 , actual: 5330 , total : 26665\n",
      "[5] train-result=0.9787, valid-result=0.8396 [8.3 s]\n",
      "pred: 10319 , actual: 10661 , total : 53331\n",
      "pred: 5426 , actual: 5330 , total : 26665\n",
      "[6] train-result=0.9847, valid-result=0.8295 [8.2 s]\n",
      "pred: 11098 , actual: 10661 , total : 53331\n",
      "pred: 5768 , actual: 5330 , total : 26665\n",
      "[7] train-result=0.9876, valid-result=0.8230 [8.2 s]\n",
      "pred: 10643 , actual: 10661 , total : 53331\n",
      "pred: 5421 , actual: 5330 , total : 26665\n",
      "[8] train-result=0.9916, valid-result=0.8206 [8.1 s]\n",
      "pred: 10649 , actual: 10661 , total : 53331\n",
      "pred: 5494 , actual: 5330 , total : 26665\n",
      "[9] train-result=0.9933, valid-result=0.8068 [8.2 s]\n",
      "pred: 10871 , actual: 10661 , total : 53331\n",
      "pred: 5211 , actual: 5330 , total : 26665\n",
      "[10] train-result=0.9940, valid-result=0.7594 [8.2 s]\n",
      "pred: 5203 , actual: 5330 , total : 26665\n",
      "#params: 765214\n",
      "pred: 10416 , actual: 10661 , total : 53331\n",
      "pred: 5244 , actual: 5330 , total : 26665\n",
      "[1] train-result=0.7843, valid-result=0.7856 [8.1 s]\n",
      "pred: 11299 , actual: 10661 , total : 53331\n",
      "pred: 5768 , actual: 5330 , total : 26665\n",
      "[2] train-result=0.8748, valid-result=0.8424 [9.1 s]\n",
      "pred: 10895 , actual: 10661 , total : 53331\n",
      "pred: 5626 , actual: 5330 , total : 26665\n",
      "[3] train-result=0.9259, valid-result=0.8534 [8.1 s]\n",
      "pred: 10141 , actual: 10661 , total : 53331\n",
      "pred: 4960 , actual: 5330 , total : 26665\n",
      "[4] train-result=0.9596, valid-result=0.8591 [8.2 s]\n",
      "pred: 10014 , actual: 10661 , total : 53331\n",
      "pred: 4927 , actual: 5330 , total : 26665\n",
      "[5] train-result=0.9753, valid-result=0.8509 [8.2 s]\n",
      "pred: 10020 , actual: 10661 , total : 53331\n",
      "pred: 4649 , actual: 5330 , total : 26665\n",
      "[6] train-result=0.9829, valid-result=0.8431 [8.2 s]\n",
      "pred: 10149 , actual: 10661 , total : 53331\n",
      "pred: 4504 , actual: 5330 , total : 26665\n",
      "[7] train-result=0.9861, valid-result=0.8289 [8.2 s]\n",
      "pred: 10462 , actual: 10661 , total : 53331\n",
      "pred: 4851 , actual: 5330 , total : 26665\n",
      "[8] train-result=0.9915, valid-result=0.8169 [8.1 s]\n",
      "pred: 10611 , actual: 10661 , total : 53331\n",
      "pred: 5303 , actual: 5330 , total : 26665\n",
      "[9] train-result=0.9933, valid-result=0.8119 [9.0 s]\n",
      "pred: 11024 , actual: 10661 , total : 53331\n",
      "pred: 5573 , actual: 5330 , total : 26665\n",
      "[10] train-result=0.9942, valid-result=0.7954 [8.2 s]\n",
      "pred: 5568 , actual: 5330 , total : 26665\n",
      "DeepFM: 0.78661 (0.02043)\n"
     ]
    }
   ],
   "source": [
    "# ------------------ DeepFM Model ------------------\n",
    "\n",
    "dfm_params = {\n",
    "    \"use_fm\": True,\n",
    "    \"use_deep\": True,\n",
    "    \"embedding_size\": 8,\n",
    "    \"dropout_fm\": [1, 1],\n",
    "    \"deep_layers\": [32],   \n",
    "    \"dropout_deep\": [0.5, 0.5, 0.5],\n",
    "    \"deep_layers_activation\": tf.nn.sigmoid,\n",
    "    \"epoch\": 10,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 0.004,\n",
    "    \"optimizer_type\": \"adam\",\n",
    "    \"batch_norm\": 1,\n",
    "    \"batch_norm_decay\": 0.997,\n",
    "    \"l2_reg\": 0.01,\n",
    "    \"verbose\": True,\n",
    "    \"eval_metric\": gini_norm,   \n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"use_sample_weights\": True,\n",
    "    \"sample_weights_dict\":{0:1,1:2},\n",
    "    \n",
    "}\n",
    "y_train_dfm, y_test_dfm = _run_base_model_dfm(dfTrain, dfTest, folds, dfm_params)\n",
    "\n",
    "# # ------------------ FM Model ------------------\n",
    "# fm_params = dfm_params.copy()\n",
    "# fm_params[\"use_deep\"] = False\n",
    "# y_train_fm, y_test_fm = _run_base_model_dfm(dfTrain, dfTest, folds, fm_params)\n",
    "\n",
    "\n",
    "# # ------------------ DNN Model ------------------\n",
    "# dnn_params = dfm_params.copy()\n",
    "# dnn_params[\"use_fm\"] = False\n",
    "# y_train_dnn, y_test_dnn = _run_base_model_dfm(dfTrain, dfTest, folds, dnn_params)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
